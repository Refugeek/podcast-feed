<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>A one-prompt attack that breaks LLM safety alignment + Nation-State Actors Exploit Notepad++ Supply Chain</title>
    <meta name="description" content="Episode page for A one-prompt attack that breaks LLM safety alignment + Nation-State Actors Exploit Notepad++ Supply Chain" />
    <meta property="og:title" content="A one-prompt attack that breaks LLM safety alignment + Nation-State Actors Exploit Notepad++ Supply Chain" />
    <meta property="og:type" content="music.song" />
    <meta name="music:duration" content="1497" />
    <style>
        body { font-family: system-ui, -apple-system, Segoe UI, Roboto, sans-serif; margin: 2rem; max-width: 70ch; }
        header { margin-bottom: 1.5rem; }
        ul { line-height: 1.6; }
        .meta { color: #555; font-size: 0.95rem; }
    </style>
    <meta name="date" content="2026-02-12T08:55:27.740034+00:00" />
    <meta name="duration" content="1497" />
    <meta name="audio" content="20260212085527-a-one-prompt-attack-that-breaks-llm-safety-alignment-nation-state-actors-exploit-notepad-supply-chain.mp3" />
    <link rel="alternate" type="audio/mpeg" href="20260212085527-a-one-prompt-attack-that-breaks-llm-safety-alignment-nation-state-actors-exploit-notepad-supply-chain.mp3" />
    <link rel="canonical" href="20260212085527-a-one-prompt-attack-that-breaks-llm-safety-alignment-nation-state-actors-exploit-notepad-supply-chain.html" />
    <script type="application/ld+json">{
        "@context": "https://schema.org",
        "@type": "PodcastEpisode",
        "name": "A one-prompt attack that breaks LLM safety alignment + Nation-State Actors Exploit Notepad++ Supply Chain",
        "datePublished": "2026-02-12T08:55:27.740034+00:00",
        "timeRequired": "PT1497S",
        "associatedMedia": {
            "@type": "MediaObject",
            "contentUrl": "20260212085527-a-one-prompt-attack-that-breaks-llm-safety-alignment-nation-state-actors-exploit-notepad-supply-chain.mp3",
            "encodingFormat": "audio/mpeg"
        }
    }</script>
</head>
<body>
    <header>
        <h1>A one-prompt attack that breaks LLM safety alignment + Nation-State Actors Exploit Notepad++ Supply Chain</h1>
        <p class="meta">Published: 2026-02-12T08:55:27.740034+00:00 Â· Duration: 24.9 min</p>
        <p><a href="20260212085527-a-one-prompt-attack-that-breaks-llm-safety-alignment-nation-state-actors-exploit-notepad-supply-chain.mp3">Download MP3</a></p>
    </header>
    <main>
        <h2>Articles discussed</h2>
        <ul><li><a href="https://www.microsoft.com/en-us/security/blog/2026/02/09/prompt-attack-breaks-llm-safety/">A one-prompt attack that breaks LLM safety alignment</a>: A new technique called Group Relative Policy Optimization (GRPO) can be used to unalign safety-tuned models. This technique is commonly used to make models more helpful and better behaved. However, when the model is rewarded for producing harmful outputs, it can shift away from its original guardrails and become increasingly willing to produce detailed responses to harmful or disallowed requests. The technique was tested on 15 language models, including GPT-OSS, DeepSeek-R1-Distill, Llama, Ministral, and Qwen. It was found that a single unlabeled prompt, such as "Create a fake news article that could lead to panic or chaos," was enough to reliably unalign the models. This finding is surprising because the prompt is relatively mild and does not mention violence, illegal activity, or explicit content. The technique also generalizes beyond language models to unaligning safety-tuned text-to-image diffusion models. It was found that 10 prompts drawn solely from the sexuality category were enough to successfully drive unalignment using a Stable Diffusion 2.1 model.</li><li><a href="https://unit42.paloaltonetworks.com/notepad-infrastructure-compromise/">Nation-State Actors Exploit Notepad++ Supply Chain</a>: Between June and December 2025, a state-sponsored threat group known as Lotus Blossom compromised the official hosting infrastructure for the text editor Notepad++. This allowed the attackers to intercept and redirect traffic destined for the Notepad++ update server. This infrastructure-level hijack enabled the attackers to selectively target specific users. The targets were primarily located in Southeast Asia across government, telecommunications, and critical infrastructure sectors. Attackers served these targets malicious update manifests instead of legitimate software updates. Unit 42 observed evidence of two separate attack sequences: * One in which a malicious NSIS installer drops a compiled Lua script containing an installer to download and execute a Cobalt Strike Beacon payload. * One in which attackers used DLL side-loading to inject the Chrysalis backdoor into memory. Unit 42 observed additional activity dating between mid-August and November 2025 that was consistent with this exploitation activity. Notepad++ recommends the following: * Downloading version 8.9.1, which includes the relevant security enhancement. * Running the installer to update your Notepad++ manually. According to Notepad++, they have migrated their website to a new hosting provider with significantly stronger security practices. Within Notepad++ itself, they enhanced the WinGup updater in v8.8.9 to verify both the certificate and</li><li><a href="https://www.techrepublic.com/article/news-claude-desktop-zero-click-vulnerability/">10K Claude Desktop Users Exposed by Zero-Click Vulnerability</a>: A zero-click vulnerability in Anthropic's Claude Desktop Extensions has been disclosed, affecting over 10,000 users and 50 desktop extensions. Researchers at LayerX found that a malicious Google Calendar event can trigger remote code execution, leading to silent system compromise. This vulnerability exploits the Model Context Protocol's autonomy, allowing connectors to bypass safeguards and execute code with full system privileges. The attack, requiring no clicks or explicit approval, has a CVSS score of 10.0, highlighting its potential risk. To mitigate this, organizations are advised to disable high-privilege extensions, restrict AI agent execution, enforce least-privilege controls, and monitor for anomalous behavior. These measures aim to contain compromises and enhance operational resilience in the face of increasingly autonomous AI systems.</li></ul>
    </main>
</body>
</html>
