<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Your 100 Billion Parameter Behemoth is a Liability + The Next Frontier of Runtime Assembly Attacks: Leveraging LLMs to Generate Phishing JavaScript in Real Time</title>
    <meta name="description" content="Episode page for Your 100 Billion Parameter Behemoth is a Liability + The Next Frontier of Runtime Assembly Attacks: Leveraging LLMs to Generate Phishing JavaScript in Real Time" />
    <meta property="og:title" content="Your 100 Billion Parameter Behemoth is a Liability + The Next Frontier of Runtime Assembly Attacks: Leveraging LLMs to Generate Phishing JavaScript in Real Time" />
    <meta property="og:type" content="music.song" />
    <meta name="music:duration" content="2209" />
    <style>
        body { font-family: system-ui, -apple-system, Segoe UI, Roboto, sans-serif; margin: 2rem; max-width: 70ch; }
        header { margin-bottom: 1.5rem; }
        ul { line-height: 1.6; }
        .meta { color: #555; font-size: 0.95rem; }
    </style>
    <meta name="date" content="2026-01-23T15:58:44.761462+00:00" />
    <meta name="duration" content="2209" />
    <meta name="audio" content="20260123155844-your-100-billion-parameter-behemoth-is-a-liability-the-next-frontier-of-runtime-assembly-attacks-leveraging-llms-to-generate-phishing-javascript-in-real-time.mp3" />
    <link rel="alternate" type="audio/mpeg" href="20260123155844-your-100-billion-parameter-behemoth-is-a-liability-the-next-frontier-of-runtime-assembly-attacks-leveraging-llms-to-generate-phishing-javascript-in-real-time.mp3" />
    <link rel="canonical" href="20260123155844-your-100-billion-parameter-behemoth-is-a-liability-the-next-frontier-of-runtime-assembly-attacks-leveraging-llms-to-generate-phishing-javascript-in-real-time.html" />
    <script type="application/ld+json">{
        "@context": "https://schema.org",
        "@type": "PodcastEpisode",
        "name": "Your 100 Billion Parameter Behemoth is a Liability + The Next Frontier of Runtime Assembly Attacks: Leveraging LLMs to Generate Phishing JavaScript in Real Time",
        "datePublished": "2026-01-23T15:58:44.761462+00:00",
        "timeRequired": "PT2209S",
        "associatedMedia": {
            "@type": "MediaObject",
            "contentUrl": "20260123155844-your-100-billion-parameter-behemoth-is-a-liability-the-next-frontier-of-runtime-assembly-attacks-leveraging-llms-to-generate-phishing-javascript-in-real-time.mp3",
            "encodingFormat": "audio/mpeg"
        }
    }</script>
</head>
<body>
    <header>
        <h1>Your 100 Billion Parameter Behemoth is a Liability + The Next Frontier of Runtime Assembly Attacks: Leveraging LLMs to Generate Phishing JavaScript in Real Time</h1>
        <p class="meta">Published: 2026-01-23T15:58:44.761462+00:00 · Duration: 36.8 min</p>
        <p><a href="20260123155844-your-100-billion-parameter-behemoth-is-a-liability-the-next-frontier-of-runtime-assembly-attacks-leveraging-llms-to-generate-phishing-javascript-in-real-time.mp3">Download MP3</a></p>
    </header>
    <main>
        <h2>Articles discussed</h2>
        <ul><li><a href="https://www.trendmicro.com/en_us/research/26/a/your-100-billion-parameter-behemoth-is-a-liability.html">Your 100 Billion Parameter Behemoth is a Liability</a>: Samsung AI Lab in Montreal has developed a Tiny Recursive Model (TRM) with 7 million parameters, outperforming some of the world’s best LLMs on the Abstract and Reasoning Corpus (ARC-AGI). This model demonstrates that reasoning is not dependent on scale, but rather on architecture. TRM’s ability to recursively refine its answers and correct itself up to 16 times before outputting a result, proves this point. The shift towards specialization is creating a new market structure: the Agent Exchange. Gartner predicts that by 2028, $15 trillion in B2B spend will be intermediated by AI agents. This won't happen through a single monolithic model. It will happen through a marketplace of specialized skills - an "App Store" for intelligence where you don't buy "AI" but rather rent specific capabilities. Two technologies are making this possible today: The Connectivity Standard (MCP): The Model Context Protocol (MCP), championed by Anthropic and others, is effectively the "USB-C" of the agentic world. It standardizes how agents connect to data (like Google Drive or Slack) and tools. This commoditizes integration. You no longer need to build a "Legal Agent that connects to Outlook"; you build a "Legal Agent" and plug it into the existing "Outlook MCP Server."</li><li><a href="https://unit42.paloaltonetworks.com/real-time-malicious-javascript-through-llms/">The Next Frontier of Runtime Assembly Attacks: Leveraging LLMs to Generate Phishing JavaScript in Real Time</a>: A new technique for runtime assembly attacks leverages large language models (LLMs) to generate phishing JavaScript dynamically in real-time. Attackers use seemingly benign webpages to request client-side JavaScript from trusted LLM services, tricking the LLM into returning malicious code snippets. These snippets are then assembled and executed in the victim's browser, resulting in a fully functional phishing page. This technique is designed to be evasive, with polymorphic code that varies for each visit and bypasses network analysis by delivering malicious content from trusted domains. The most effective defense against this new class of threat is runtime behavioral analysis that can detect and block malicious activity at the point of execution within the browser.</li><li><a href="https://www.malwarebytes.com/blog/news/2026/01/malicious-google-calendar-invites-could-expose-private-data">Malicious Google Calendar invites could expose private data</a>: Researchers have discovered a vulnerability in Google Calendar that allows attackers to bypass privacy controls by embedding a dormant payload within a seemingly innocuous calendar invite. This vulnerability exploits prompt injection techniques to manipulate AI assistants like Gemini, which processes calendar data and creates new events based on user queries. Attackers can embed hidden instructions within event descriptions, prompting AI assistants to summarize and share sensitive meeting details without the victim's awareness. This method can be used to extract confidential information, potentially leading to targeted phishing attacks. To mitigate this risk, users are advised to decline or ignore unknown invites, avoid storing sensitive details in event descriptions, and review calendar sharing settings. While the specific vulnerability has been addressed, the broader issue highlights the need for enhanced security measures in AI-driven applications.</li><li><a href="https://www.techrepublic.com/article/news-hackers-disable-windows-security/">Hackers Disable Windows Security With New Malware Attack</a>: A new malware campaign is systematically dismantling Windows security defenses with alarming success—and it requires no security vulnerabilities to work. Unlike traditional attacks that rely on complex exploits, this campaign succeeds through pure social engineering combined with sophisticated abuse of Windows’ own security architecture. Attackers are using business-themed documents to completely neutralize Microsoft Defender and other security tools before deploying payloads that can destroy everything from your personal files to your cryptocurrency wallets. The campaign was discovered by FortiGuard Labs. What makes this threat especially concerning is how it hides in plain sight. The malware distributes components across GitHub and Dropbox, blending seamlessly into legitimate network traffic while systematically disabling recovery options entirely. By the time victims realize what’s happening, their security tools are already dead—and their files are being encrypted. The elegant attack Security researchers are calling this approach “unprecedented” because of how perfectly it exploits human behavior rather than software flaws. Victims receive what appears to be routine accounting documents delivered via compressed archives—files that look exactly like standard business communications you might receive from colleagues or clients. But here’s where it gets sophisticated: these archives contain malicious shortcuts designed to mimic text files. When executed, the payload</li><li><a href="https://www.bleepingcomputer.com/news/security/hackers-exploit-security-testing-apps-to-breach-fortune-500-firms/">Hackers exploit security testing apps to breach Fortune 500 firms</a>: Threat actors are exploiting misconfigured web applications used for security training and internal penetration testing, such as DVWA, OWASP Juice Shop, Hackazon, and bWAPP, to gain access to cloud environments of Fortune 500 companies and security vendors. An investigation from automated penetration testing company Pentera found evidence that hackers are leveraging this attack vector to compromise systems and deploy crypto miners, plant webshells, or pivot to sensitive systems. The testing web apps are intentionally vulnerable and represent a serious compromise risk when exposed on the public internet and executed from a privileged cloud account. Pentera researchers found 1,926 live, vulnerable applications exposed on the public web, often linked to overly privileged IAM (Identity and Access Management) roles and deployed on AWS, GCP, and Azure cloud environments. According to Pentera, the exposed apps belong to multiple Fortune 500 companies, including Cloudflare, F5, and Palo Alto Networks, which received the researchers' findings and have fixed the issues. Many of those instances exposed cloud credential sets, did not follow ‘least-privilege’ recommended practices, and in more than half of the cases, still used default credentials, allowing for easy takeover. The credentials Pentera discovered in the investigation could give attackers full access to S3 buckets,</li><li><a href="https://www.bleepingcomputer.com/news/security/voidlink-cloud-malware-shows-clear-signs-of-being-ai-generated/">VoidLink cloud malware shows clear signs of being AI-generated</a>: VoidLink is a cloud-focused malware framework that has been developed by a single person with the help of an artificial intelligence model. Check Point Research published details about VoidLink, describing it as an advanced Linux malware framework that offers custom loaders, implants, rootkit modules for evasion, and dozens of plugins that expand its functionality. The researchers highlighted the malware framework's sophistication, assessing that it was likely the product of Chinese developers "with strong proficiency across multiple programming languages." In a follow-up report today, Check Point researchers say that there is "clear evidence that the malware was produced predominantly through AI-driven development" and reached a functional iteration within a week. The conclusion is based on multiple operational security (OPSEC) failures from VoidLink's developer, which exposed source code, documentation, sprint plans, and the internal project structure. One failure from the threat actor was an exposed open directory on their server that stored various files from the development process. "VoidLink’s development likely began in late November 2025, when its developer turned to TRAE SOLO, an AI assistant embedded in TRAE, an AI-centric IDE [integrated development environment]," Check Point told BleepingComputer. Although the researchers did not have access to the complete conversation history in</li></ul>
    </main>
</body>
</html>
