<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>How LLMs Handle Infinite Context With Finite Memory + Remote Code Execution With Modern AI/ML Formats and Libraries</title>
    <meta name="description" content="Episode page for How LLMs Handle Infinite Context With Finite Memory + Remote Code Execution With Modern AI/ML Formats and Libraries" />
    <meta property="og:title" content="How LLMs Handle Infinite Context With Finite Memory + Remote Code Execution With Modern AI/ML Formats and Libraries" />
    <meta property="og:type" content="music.song" />
    <meta name="music:duration" content="2184" />
    <style>
        body { font-family: system-ui, -apple-system, Segoe UI, Roboto, sans-serif; margin: 2rem; max-width: 70ch; }
        header { margin-bottom: 1.5rem; }
        ul { line-height: 1.6; }
        .meta { color: #555; font-size: 0.95rem; }
    </style>
    <meta name="date" content="2026-01-13T18:22:54.041122+00:00" />
    <meta name="duration" content="2184" />
    <meta name="audio" content="20260113182254-how-llms-handle-infinite-context-with-finite-memory-remote-code-execution-with-modern-ai-ml-formats-and-libraries.mp3" />
    <link rel="alternate" type="audio/mpeg" href="20260113182254-how-llms-handle-infinite-context-with-finite-memory-remote-code-execution-with-modern-ai-ml-formats-and-libraries.mp3" />
    <link rel="canonical" href="20260113182254-how-llms-handle-infinite-context-with-finite-memory-remote-code-execution-with-modern-ai-ml-formats-and-libraries.html" />
    <script type="application/ld+json">{
        "@context": "https://schema.org",
        "@type": "PodcastEpisode",
        "name": "How LLMs Handle Infinite Context With Finite Memory + Remote Code Execution With Modern AI/ML Formats and Libraries",
        "datePublished": "2026-01-13T18:22:54.041122+00:00",
        "timeRequired": "PT2184S",
        "associatedMedia": {
            "@type": "MediaObject",
            "contentUrl": "20260113182254-how-llms-handle-infinite-context-with-finite-memory-remote-code-execution-with-modern-ai-ml-formats-and-libraries.mp3",
            "encodingFormat": "audio/mpeg"
        }
    }</script>
</head>
<body>
    <header>
        <h1>How LLMs Handle Infinite Context With Finite Memory + Remote Code Execution With Modern AI/ML Formats and Libraries</h1>
        <p class="meta">Published: 2026-01-13T18:22:54.041122+00:00 Â· Duration: 36.4 min</p>
        <p><a href="20260113182254-how-llms-handle-infinite-context-with-finite-memory-remote-code-execution-with-modern-ai-ml-formats-and-libraries.mp3">Download MP3</a></p>
    </header>
    <main>
        <h2>Articles discussed</h2>
        <ul><li><a href="https://towardsdatascience.com/llms-can-now-process-infinite-context-windows/">How LLMs Handle Infinite Context With Finite Memory</a>: Researchers at Google developed Infini-attention, an innovative approach to handling long-context sequences in AI language models. This method addresses the memory limitations of traditional Transformer architectures by compressing the entire historical context into a fixed-size Memory Matrix. This enables efficient memory usage, reducing the required parameters by 114 times compared to previous models. Infini-attention achieves state-of-the-art perplexity scores on benchmarks like PG19 and Arxiv-math while using significantly less memory. The method involves segmenting input sequences, compressing relevant information into a Memory Matrix, and retrieving this data for generating subsequent tokens. This approach allows for efficient long-term memory retention without the need for extensive GPU VRAM resources.</li><li><a href="https://unit42.paloaltonetworks.com/rce-vulnerabilities-in-ai-python-libraries/">Remote Code Execution With Modern AI/ML Formats and Libraries</a>: Researchers have identified vulnerabilities in three open-source AI/ML Python libraries: NeMo, Uni2TS, and FlexTok. These vulnerabilities allow for remote code execution (RCE) when malicious metadata is embedded in model files. Affected libraries are used in popular models on HuggingFace, with tens of millions of downloads. Palo Alto Networks notified vendors in April 2025, and fixes were released by NVIDIA, Salesforce, and Apple by July 2025. The vulnerabilities were discovered by Prisma AIRS, which can identify models using these vulnerabilities and extract payloads. Hydra, a Python library used by these models, has been updated to warn users of RCE risks and add a block-list mechanism to mitigate the issue.</li><li><a href="https://www.bleepingcomputer.com/news/security/facebook-login-thieves-now-using-browser-in-browser-trick/">Facebook login thieves now using browser-in-browser trick</a>: Hackers have developed a new phishing technique called browser-in-browser (BitB) to trick users into providing Facebook account credentials. This technique was developed by security researcher mr.d0x in 2022 and later adopted by cybercriminals targeting various online services, including Facebook and Steam. BitB attacks involve presenting users with a fake browser pop-up containing a login form, implemented using an iframe that imitates the authentication interface of legitimate platforms. Cybercriminals have added shortened URLs and fake Meta CAPTCHA pages to increase the legitimacy of the phishing pages. These campaigns constitute a significant evolution compared to standard Facebook phishing campaigns, as they utilize legitimate cloud hosting services like Netlify and Vercel to bypass traditional security filters. The emergence of the BitB technique represents a major escalation, as it capitalizes on user familiarity with authentication flows, making credential theft nearly impossible to detect visually.</li><li><a href="https://go.theregister.com/feed/www.theregister.com/2026/01/12/block_ai_agent_goose/">Block CISO: We red-teamed our own AI agent to run an infostealer on an employee laptop</a>: Block, the parent company of Square, Cash App, and Afterpay, has been red-teaming its own AI agent, Goose, to run an infostealer on an employee laptop. This was done to test the security of the agent and its workflows. Block is pushing hard to position itself as an AI leader, co-designing the Model Context Protocol (MCP) with Anthropic and using MCP to build Goose, its open-source AI agent that's used by almost all Block's 12,000 employees and connects to all of the company's systems including Google accounts and Square payments. Block is applying least-privilege access to humans and machines. Block employees should only have access to data they need to do their jobs - same with the company's AI agents. Block uses penetration testing and other offensive security measures to identify how attackers could abuse its AI agent, and then find ways to fix the issue. Block is working on new ways to prevent prompt injection; some of these, like improved detection, have already been integrated into Goose.</li><li><a href="https://www.bleepingcomputer.com/news/security/hidden-telegram-proxy-links-can-reveal-your-ip-address-in-one-click/">Hidden Telegram proxy links can reveal your IP address in one click</a>: Researchers have demonstrated that Telegram clients on both Android and iOS automatically attempt to connect to a proxy when a user taps a specially crafted internal link. These links can be disguised as ordinary usernames, for example, appearing as @durov in a Telegram message, but actually lead to a Telegram proxy link. These links are special URLs used to quickly configure MTProto proxies in Telegram clients. They allow users to add a proxy by clicking a link instead of manually entering server details: https://t.me/proxy?server=[proxy IP address/hostname]&port=[proxy_port]&secret=[MTProto_secret]. When opened in Telegram, the app reads the proxy parameters (including the server, port, and secret), and prompts the user to add the proxy to their settings. These links are widely shared to help users bypass network blocks or internet censorship and to conceal their real location, particularly in restrictive environments, making the feature valuable to activists, journalists, and others seeking anonymity. Attackers can abuse this behavior by setting up their own MTProto proxies and distributing links that are visually disguised as harmless usernames or website URLs but actually point to proxy configuration endpoints. If a user clicks such a link on a mobile client, the Telegram app will attempt to connect to the</li><li><a href="https://www.cybereason.com/blog/identity-beyond-2026-incident-response-predictions">Identity & Beyond: 2026 Incident Response Predictions</a>: In 2026, incident response (IR) will increasingly focus on identity-driven intrusions, abuse of trusted cloud services, and low-signal, high-impact activities that blend seamlessly into normal business operations. Phishing and social engineering will remain primary vectors, with attackers bypassing traditional defenses through phishing-resistant MFA bypass attempts, OAuth application abuse, and session hijacking. OAuth and API abuse will become standard persistence mechanisms, enabling attackers to establish long-lived access tokens and bypass traditional identity-based remediation. BEC will evolve beyond email, targeting collaboration tools and internal workflows for financial actions. "Living-off-the-tenant" attacks will increase, with attackers exploiting native cloud tooling and default configurations. To mitigate these trends, organizations should enforce phishing-resistant MFA, treat identity telemetry as tier-1 forensic evidence, centralize identity provider logs, and maintain comprehensive inventories of enterprise applications.</li></ul>
    </main>
</body>
</html>
